# Этот проект представляет собой автоматизированный скрипт для извлечения информации с веб-страницы с помощью Selenium и BeautifulSoup. Скрипт выполняет следующие действия:

1. Открывает сайт https://ggsel.net/wheel.
2. Находит и нажимает кнопку, инициирующую игру (веб-колесо).
3. После того как откроется новое окно, извлекает данные с этой страницы.
4. Сохраняет результат в файл `results.txt`.

## Зависимости

## Перед запуском скрипта необходимо установить следующие библиотеки:

1. **Selenium** - для автоматизации браузера.
2. **BeautifulSoup** (собирается через библиотеку `lxml`) - для парсинга HTML.
3. **ChromeDriver** - для управления браузером Chrome (его необходимо скачать и указать путь в системных переменных или в скрипте).

## Чтобы установить необходимые зависимости, выполните следующую команду:

```bash
pip install selenium beautifulsoup4 lxml
```

## Установка и запуск

1. Убедитесь, что у вас установлен **ChromeDriver**. Его можно скачать по следующей ссылке: [https://sites.google.com/a/chromium.org/chromedriver/](https://sites.google.com/a/chromium.org/chromedriver/).
2. Если вы хотите запускать скрипт в фоновом режиме (без открытия окна браузера), раскомментируйте строку `chrome_options.add_argument("--headless")`.
3. Для запуска просто выполните скрипт:

```bash
python script.py
```

## Функциональность

1. Скрипт использует Selenium для автоматизации браузера. Он открывает страницу и взаимодействует с ней.
2. После выполнения действий на странице, BeautifulSoup парсит HTML-код, чтобы извлечь нужную информацию.
3. Извлечённая информация сохраняется в файл `results.txt`.

### Пример содержимого файла `results.txt`:
```
Текст1 Значение1
Текст2 Значение2
```

## Возможности для улучшения

1. Добавить обработку ошибок для улучшения стабильности работы.
2. Расширить функционал для извлечения других данных с сайта.
3. Настроить логирование для удобства отслеживания работы скрипта.
